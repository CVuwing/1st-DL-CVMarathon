{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n",
      "(50000, 32, 32, 3)\n",
      "(32, 32, 3)\n",
      "mean: 120.70756512369792\n",
      "std: 64.1500758911213\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "print(x_train[0].shape) #(50000, 32, 32, 3)\n",
    "# cv2.imshow('R', x_train[100])\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        print('mean:',mean)  \n",
    "        print('std:',std)  \n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       ...,\n",
       "       [5],\n",
       "       [1],\n",
       "       [7]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder(categories='auto')\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WilsonChen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 3.9624 - accuracy: 0.4952\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 0.8525 - accuracy: 0.7046\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 186s 4ms/step - loss: 0.6990 - accuracy: 0.7555\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.5738 - accuracy: 0.8001\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 199s 4ms/step - loss: 0.4728 - accuracy: 0.8334\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.3865 - accuracy: 0.8630\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 207s 4ms/step - loss: 0.3315 - accuracy: 0.8824\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.2686 - accuracy: 0.9050\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 193s 4ms/step - loss: 0.2453 - accuracy: 0.9127\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.2124 - accuracy: 0.9242\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.1914 - accuracy: 0.9326\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 218s 4ms/step - loss: 0.1732 - accuracy: 0.9392\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 234s 5ms/step - loss: 0.1568 - accuracy: 0.9450\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 236s 5ms/step - loss: 0.1397 - accuracy: 0.9507\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.1351 - accuracy: 0.9544\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 226s 5ms/step - loss: 0.1195 - accuracy: 0.9586\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 225s 5ms/step - loss: 0.1098 - accuracy: 0.9628\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.1164 - accuracy: 0.9608\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 230s 5ms/step - loss: 0.1032 - accuracy: 0.9662\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 253s 5ms/step - loss: 0.0939 - accuracy: 0.9680\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 229s 5ms/step - loss: 0.0915 - accuracy: 0.9695\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 271s 5ms/step - loss: 0.0864 - accuracy: 0.9709\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 238s 5ms/step - loss: 0.0800 - accuracy: 0.9730\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 242s 5ms/step - loss: 0.0767 - accuracy: 0.9739\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.0718 - accuracy: 0.9760\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 248s 5ms/step - loss: 0.0728 - accuracy: 0.9756\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 235s 5ms/step - loss: 0.0666 - accuracy: 0.9768\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 217s 4ms/step - loss: 0.0685 - accuracy: 0.9772\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.0739 - accuracy: 0.9748\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.0637 - accuracy: 0.9785\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.0485 - accuracy: 0.9842\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 0.0567 - accuracy: 0.9810\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 257s 5ms/step - loss: 0.0533 - accuracy: 0.9820\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 227s 5ms/step - loss: 0.0613 - accuracy: 0.9796\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 227s 5ms/step - loss: 0.0409 - accuracy: 0.9859\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.0512 - accuracy: 0.9830\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 0.0520 - accuracy: 0.9832\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 232s 5ms/step - loss: 0.0469 - accuracy: 0.9843\n",
      "Epoch 39/100\n",
      " 2600/50000 [>.............................] - ETA: 4:01 - loss: 0.0324 - accuracy: 0.9912"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "##'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "##卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "##flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "##FC\n",
    "classifier.add(Dense(100)) #output_dim=100,activation=relu\n",
    "\n",
    "##輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "##超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
